
# <p style="text-align:center">ML Project Guide </p>

üìã **Exploratory Data Analysis** `video 27/30`

* Objectif :    
    - Pr√©dire si une personne est infect√©e en fonction des donn√©es cliniques disponibles
* M√©trique adapt√©e choisie ? (ex : F1, Recall...)
    - F1 min 50% et recall min 70%

**I - Analyse de la forme :** `video 28/30`

* [X]Ai-je identifi√© la variable cible (target) ?
    - target = data["SARS-Cov-2 exam result	"]

* [X]Ai-je not√© le nombre de lignes et colonnes du dataset ?
    - (5644, 111)

* [X]Les types de variables sont-ils bien identifi√©s (num√©riques, cat√©gorielles...) ? (sns.pie and value_counts)
    -   Num√©rique pour la plupart sauf pour le r√©sultat test et l' ID

* [X]Ai-je rep√©r√© les valeurs manquantes ?
    - La plupart des colonnes √† partir de la 7eme lorsque la personne est n√©gative


**II - Analyse du fond :**

* Ai-je visualis√© la distribution de la target (histogramme, boxplot) ?
    - 10% positive test => Classes pas √©quilibr√©es => utiliser score F1
* Est-ce que je comprends bien la signification de chaque variable ?
    - 
* Ai-je explor√© les relations entre les features et la target ?
* Ai-je identifi√© les valeurs aberrantes (outliers) ?

---

üìã **Pre-processing** `video 29/30`

Objectif : Pr√©parer les donn√©es pour les algorithmes de machine learning.

* Ai-je s√©par√© les donn√©es en Train Set et Test Set ?
* Les valeurs manquantes (NaN) ont-elles √©t√© trait√©es (suppression ou imputation) ?
* Ai-je encod√© les variables cat√©gorielles ?
* Les outliers probl√©matiques ont-ils √©t√© trait√©s ou supprim√©s ?
* Ai-je s√©lectionn√© les variables les plus utiles (feature selection) ?
* Ai-je cr√©√© de nouvelles variables pertinentes (feature engineering) ?
* Les variables num√©riques sont-elles mises √† l‚Äô√©chelle (normalisation / standardisation) ?

---

üìã **Modelling**

Objectif : Construire un mod√®le capable d‚Äôatteindre l‚Äôobjectif d√©fini.

* Ai-je choisi une fonction d‚Äô√©valuation adapt√©e (F1, Recall, etc.) ?
* Ai-je test√© plusieurs types de mod√®les ?
* Ai-je utilis√© GridSearchCV ou une autre m√©thode pour optimiser les hyperparam√®tres ?
* Ai-je analys√© les erreurs du mod√®le ?
* Suis-je revenu √† l‚Äô√©tape de preprocessing ou EDA si n√©cessaire ?
* Ai-je √©tudi√© les courbes d‚Äôapprentissage (learning curves) pour prendre des d√©cisions √©clair√©es ?














































# <p style="text-align:center">ML Project Guide </p>

## 1. D√©finir un objectif mesurable:

**Objectif**: Pr√©dire si une personne est infect√©e en fonction des donn√©es cliniques disponibles

**M√©trique**: ~~accuracy min => 90%~~ non car si 1/10 infect√©e et que model pr√©dit toujours saine il aura 90% donc **F1 min 50% et recall min 70%**

## 2. EDA(Exploraty Data Analysis) `video 27/30`


#### I. Analyse de la forme

Avant de plonger dans l'analyse des donn√©es, il est crucial de bien comprendre leur **structure** et leurs caract√©ristiques fondamentales. Cette √©tape, souvent sous-estim√©e, pose les bases d'une mod√©lisation r√©ussie.

* **Identification de la target** : C'est la variable que vous cherchez √† pr√©dire ou √† expliquer. La conna√Ætre pr√©cis√©ment est le point de d√©part de toute analyse.
* **Nombre de lignes et de colonnes** : Ces dimensions vous donnent une premi√®re id√©e de la taille de votre jeu de donn√©es. Un grand nombre de lignes peut n√©cessiter des optimisations de performance, tandis qu'un grand nombre de colonnes (features) peut indiquer le besoin de r√©duction de dimensionnalit√©.
* **Identification des valeurs manquantes** : Les donn√©es manquantes (NaN pour "Not a Number") sont monnaie courante et peuvent biaiser vos analyses. Il est essentiel de les rep√©rer t√¥t pour choisir la strat√©gie de traitement ad√©quate.
* **Types de variables** : Distinguer les variables num√©riques (continues ou discr√®tes) des variables cat√©gorielles (nominales ou ordinales) est fondamental. Chaque type de variable n√©cessite un traitement sp√©cifique avant d'√™tre utilis√© dans un mod√®le.



#### II. Analyse du fond

Une fois la structure appr√©hend√©e, il est temps de comprendre le **contenu** de vos donn√©es et les relations qu'elles entretiennent. Cette phase d'exploration est essentielle pour d√©gager des insights et identifier les probl√®mes potentiels.

* **Visualisation de la target (histogramme/boxplot)** : Visualiser la distribution de votre variable cible vous aide √† comprendre sa nature (sym√©trique, asym√©trique, pr√©sence d'outliers) et √† orienter le choix de vos mod√®les.
* **Compr√©hension des diff√©rentes variables (recherche)** : Ne vous contentez pas des noms de colonnes. Effectuez des recherches sur la signification de chaque variable dans votre domaine d'√©tude. Une bonne compr√©hension m√©tier est inestimable.
* **Visualisation des relations : features/target** : Explorez comment chaque variable explicative (`feature`) est li√©e √† votre variable cible. Des graphiques de dispersion, des boxplots group√©s ou des corr√©lations peuvent r√©v√©ler des tendances importantes.
* **Identification des outliers** : Les valeurs aberrantes peuvent significativement fausser les r√©sultats de vos mod√®les. Il est crucial de les identifier pour d√©cider si elles doivent √™tre trait√©es, transform√©es ou supprim√©es.

---

## 3. Pre-processing `video 28/30`


### Objectif : Pr√©parer les Donn√©es pour le Machine Learning

Le but est de transformer vos donn√©es brutes en un format optimal pour les algorithmes de machine learning. Voici les √©tapes cl√©s :

* **Cr√©ation du Train Set / Test Set** : S√©parez vos donn√©es en ensembles d'entra√Ænement et de test pour √©valuer la performance de votre mod√®le.
* **√âlimination des NaN** : G√©rez les valeurs manquantes via des m√©thodes comme `dropna()`, l'imputation, ou le traitement des colonnes "vides".
* **Encodage** : Convertissez les variables cat√©gorielles en un format num√©rique compr√©hensible par les mod√®les.
* **Suppression des outliers n√©fastes au mod√®le** : Identifiez et traitez les valeurs aberrantes qui pourraient biaiser l'apprentissage.
* **Feature selection** : S√©lectionnez les variables les plus pertinentes pour am√©liorer la performance et r√©duire la complexit√© du mod√®le.
* **Feature engineering** : Cr√©ez de nouvelles variables √† partir des existantes pour enrichir l'information de votre dataset.
* **Feature scaling** : Normalisez ou standardisez vos variables num√©riques pour assurer que toutes les caract√©ristiques contribuent √©quitablement au mod√®le.


## 4. Modelling `video 29/30`

 
### Objectif : D√©velopper un Mod√®le de Machine Learning Robuste

Une fois vos donn√©es pr√©par√©es, l'√©tape suivante consiste √† construire et √† affiner un mod√®le capable de r√©pondre √† votre probl√©matique. C'est ici que l'apprentissage automatique prend tout son sens.

* **D√©finir une fonction d'√©valuation** : Avant m√™me de commencer √† entra√Æner des mod√®les, il est crucial de choisir la bonne m√©trique pour mesurer leur performance. Que ce soit la pr√©cision, le rappel, le F1-score, le RMSE ou autre, votre fonction d'√©valuation doit refl√©ter l'objectif de votre projet et la nature de vos donn√©es.

* **Entra√Ænement de diff√©rents mod√®les** : Ne mettez pas tous vos ≈ìufs dans le m√™me panier ! Il est souvent b√©n√©fique d'exp√©rimenter avec plusieurs types d'algorithmes (r√©gression lin√©aire, arbres de d√©cision, for√™ts al√©atoires, boosting, SVM, etc.). Chaque mod√®le a ses forces et ses faiblesses, et celui qui convient le mieux √† vos donn√©es n'est pas toujours √©vident √† deviner.

* **Optimisation avec GridSearchCV** : Une fois que vous avez identifi√© quelques mod√®les prometteurs, l'optimisation des hyperparam√®tres devient essentielle. `GridSearchCV` (ou d'autres m√©thodes comme `RandomizedSearchCV`) vous permet de tester syst√©matiquement diff√©rentes combinaisons de param√®tres pour trouver la configuration qui maximise la performance de votre mod√®le selon votre fonction d'√©valuation.

* **Analyse des erreurs et retour au Preprocessing / EDA** : Un mod√®le n'est jamais parfait. L'analyse des erreurs (o√π et pourquoi le mod√®le se trompe) est une √©tape critique. Ces erreurs peuvent r√©v√©ler des lacunes dans votre pr√©traitement (`Preprocessing`) ou des informations manquantes dans votre analyse exploratoire des donn√©es (`EDA`). N'h√©sitez pas √† faire des allers-retours entre ces √©tapes pour am√©liorer votre mod√®le.

* **Learning Curve et prise de d√©cision** : Les courbes d'apprentissage sont un outil puissant pour diagnostiquer si votre mod√®le souffre de sous-apprentissage (biais √©lev√©) ou de surapprentissage (variance √©lev√©e). En analysant ces courbes, vous pouvez prendre des d√©cisions √©clair√©es : collecter plus de donn√©es, simplifier ou complexifier le mod√®le, ou ajuster les hyperparam√®tres.
---